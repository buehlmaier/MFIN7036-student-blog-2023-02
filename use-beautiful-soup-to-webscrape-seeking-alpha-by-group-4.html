<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students 2023" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Use Beautiful Soup to webscrape Seeking Alpha (by &#34;Group 4&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/use-beautiful-soup-to-webscrape-seeking-alpha-by-group-4.html" />
<meta property="og:description" content="By Group 4 Seeking Alpha is a website that provides financial analysis and stock ideas. In this project, we use Beautiful Soup to webscrape stock ideas on Seeking Alpha in the past three months in the healthcare industry. Import libraries import requests import re from bs4 import BeautifulSoup import time …" />
<meta property="og:site_name" content="MFIN7036 Student Blog 2023" />
<meta property="og:article:author" content="MFIN7036 Students 2023" />
<meta property="og:article:published_time" content="2023-03-17T23:21:30+08:00" />
<meta name="twitter:title" content="Use Beautiful Soup to webscrape Seeking Alpha (by &#34;Group 4&#34;) ">
<meta name="twitter:description" content="By Group 4 Seeking Alpha is a website that provides financial analysis and stock ideas. In this project, we use Beautiful Soup to webscrape stock ideas on Seeking Alpha in the past three months in the healthcare industry. Import libraries import requests import re from bs4 import BeautifulSoup import time …">

        <title>Use Beautiful Soup to webscrape Seeking Alpha (by &#34;Group 4&#34;)  · MFIN7036 Student Blog 2023
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog 2023 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/"><span class=site-name>MFIN7036 Student Blog 2023</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2023-02
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/use-beautiful-soup-to-webscrape-seeking-alpha-by-group-4.html">
                Use Beautiful Soup to webscrape Seeking Alpha (by "Group 4")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group 4</p>
<p>Seeking Alpha is a website that provides financial analysis and stock ideas. In this
project, we use Beautiful Soup to webscrape stock ideas on Seeking Alpha in the past three months in the healthcare industry.</p>
<h2>Import libraries</h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">time</span>
</code></pre></div>

<h2>Obtain urls for all articles</h2>
<p>To webscrape the long ideas and news on Seeking Alpha, we first need to obtain the urls for all articles.
We use the url for the contents page as the starting point. </p>
<p>The contents page of the long ideas and news on Seeking Alpha is as follows:</p>
<p><img alt="Wechat" src="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/images/Group4-Post04_WechatIMG48.jpg"></p>
<p>We use the <em><strong>requests</strong></em> to request the html of the contents page. Then, 
we use the <strong><em>Beautiful Soup</em></strong> to parse the html and obtain the urls suffix for each article, and save the urls in a list. </p>
<div class="highlight"><pre><span></span><code><span class="n">lst_url</span> <span class="o">=</span> <span class="s1">&#39;https://seekingalpha.com/stock-ideas/healthcare&#39;</span> <span class="c1"># url for the contents page</span>
<span class="n">r_lst</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://seekingalpha.com/stock-ideas/healthcare&#39;</span><span class="p">)</span> <span class="c1"># request the html</span>
<span class="n">s_lst</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r_lst</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="s1">&#39;lxml&#39;</span><span class="p">)</span> <span class="c1"># parse the html</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">lst</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># create an empty list to store the urls</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">s_lst</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,{</span><span class="s2">&quot;data-test-id&quot;</span><span class="p">:</span><span class="s2">&quot;post-list-item-title&quot;</span><span class="p">}):</span> <span class="c1"># find all the articles</span>
    <span class="n">address</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span> <span class="c1"># get the url suffix for each article</span>
    <span class="n">lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">address</span><span class="p">)</span> <span class="c1"># append the url suffix to the list</span>
</code></pre></div>

<h2>Define functions to obtain the data we need</h2>
<p>We define the following functions to obtain the data we need:
1. get_text: to obtain the text of each article
2. get_time: to obtain the time of each article
3. get_stock: to obtain the stock mainly discussed in each article
4. get_follower: to obtain the number of followers of the writer
5. get_like: to obtain the number of likes of each article</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_text</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span> <span class="o">+</span> <span class="n">i</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span> 
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">get_time</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;meta&#39;</span><span class="p">,</span><span class="nb">property</span> <span class="o">=</span> <span class="s1">&#39;article:published_time&#39;</span><span class="p">):</span> 
        <span class="n">time</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;content&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">time</span>

<span class="k">def</span> <span class="nf">get_stock</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[(](.*?)[)]&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span> <span class="c1"># to obtain the content in the brackets</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;xs-YW&quot;</span><span class="p">})))[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># to obtain the stock</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span>

<span class="k">def</span> <span class="nf">get_follower</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;tF-RY aw-gT aw-g7 aw-hm rT-Si ag-gn aw-gT aw-g7 aw-hm&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">get_like</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[(](.*?)[)]&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span> <span class="c1"># to obtain the content in the brackets</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span><span class="s2">&quot;wS-jk&quot;</span><span class="p">})))[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># to obtain the number of likes</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</code></pre></div>

<p>Some points to note:
1. We use the try and except function to skip the articles that do not have the data we need, or else the program will stop running.
2. Regular expression is to obtain the number of likes of each article, 
because the number of likes is in the format of 'Like (1)', and we only need the number 1.
3. Find text in <p> tag rather than get text in the whole html, because the main text of each article is in the <p> tag. 
4. To find specific content, we can find the corresponding tags and class by using the inspect function in the browser. 
5. To achieve the same function as the inspect function, we can use the find_all function, and specify the class using a dictionary.</p>
<h2>Obtain and save data we need</h2>
<p>In this part, we add 'https://seekingalpha.com' to the each url suffix we obtained in the previous part 
to request the html of each article, and parse the html to obtain the data we need.
Then, we write the data to a csv file.</p>
<p>In the request part, to avoid the risk of being blocked by the website, we do the following:
1. We use a for loop to request the html of each article one by one. 
2. We set the timeout to 10 seconds, and use the time library to set a sleep time of 1 second between each request. 
3. We also use the try and except function to avoid the risk of being blocked by the website.</p>
<div class="highlight"><pre><span></span><code><span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;stk&#39;</span><span class="p">,</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">,</span><span class="s1">&#39;followers&#39;</span><span class="p">,</span><span class="s1">&#39;likes&#39;</span><span class="p">]</span> 
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;/Users/file/text.csv&#39;</span><span class="p">,</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">encoding</span> <span class="o">=</span> <span class="s1">&#39;UTF8&#39;</span><span class="p">,</span> <span class="n">newline</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span> <span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> 
    <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">header</span><span class="p">)</span> 
    <span class="k">for</span> <span class="n">address</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span> 
        <span class="k">try</span><span class="p">:</span> 
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>  <span class="c1"># set a sleep time of 1 second between each request</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://seekingalpha.com&#39;</span> <span class="o">+</span> <span class="n">address</span><span class="p">,</span> <span class="n">timeout</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># request the html</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="s1">&#39;lxml&#39;</span><span class="p">)</span> <span class="c1"># parse the html</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">get_text</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="c1"># get the text</span>
            <span class="n">time</span> <span class="o">=</span> <span class="n">get_time</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="c1"># get the time</span>
            <span class="n">stk</span> <span class="o">=</span>  <span class="n">get_stock</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="c1"># get the stock</span>
            <span class="n">follow</span> <span class="o">=</span> <span class="n">get_follower</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="c1"># get the number of followers</span>
            <span class="n">like</span> <span class="o">=</span> <span class="n">get_like</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="c1"># get the number of likes</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">((</span><span class="n">stk</span><span class="p">,</span><span class="n">time</span><span class="p">,</span><span class="n">text</span><span class="p">,</span><span class="n">follow</span><span class="p">,</span><span class="n">like</span><span class="p">))</span> <span class="c1"># write the data to the csv file</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span> 
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>

<p>Now the data we need is saved in the csv file, the format is as follows:</p>
<p><img alt="Wechat" src="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/images/Group4-Post04_WechatIMG50.jpg"></p>
<p>The next step is to clean the data and do some analysis. Thanks for reading!</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2023-03-17T23:21:30+08:00">Fri 17 March 2023</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2023-02" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2023-02/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>